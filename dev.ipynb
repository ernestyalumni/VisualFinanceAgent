{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. SUMMARY FROM PDF IMAGES USING GROQ\n",
    "2. COLPALI VECTORSTORE TO INDEX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/recoverx/astarag/VisualFinanceAgent/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:4531: RuntimeWarning: coroutine 'get_summary' was never awaited\n",
      "  gc.collect()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/recoverx/astarag/VisualFinanceAgent/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:4531: RuntimeWarning: coroutine 'AsyncCompletions.create' was never awaited\n",
      "  gc.collect()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing file: finance/jll-asia-pacific-capital-tracker-3q23 (1).pdf\n",
      "Added page 1 of document 0 to index.\n",
      "Added page 2 of document 0 to index.\n",
      "Added page 3 of document 0 to index.\n",
      "Added page 4 of document 0 to index.\n",
      "Added page 5 of document 0 to index.\n",
      "Added page 6 of document 0 to index.\n",
      "Added page 7 of document 0 to index.\n",
      "Added page 8 of document 0 to index.\n",
      "Added page 9 of document 0 to index.\n",
      "Added page 10 of document 0 to index.\n",
      "Added page 11 of document 0 to index.\n",
      "Added page 12 of document 0 to index.\n",
      "Added page 13 of document 0 to index.\n",
      "Added page 14 of document 0 to index.\n",
      "Added page 15 of document 0 to index.\n",
      "Added page 16 of document 0 to index.\n",
      "Added page 17 of document 0 to index.\n",
      "Added page 18 of document 0 to index.\n",
      "Added page 19 of document 0 to index.\n",
      "Added page 20 of document 0 to index.\n",
      "Added page 21 of document 0 to index.\n",
      "Added page 22 of document 0 to index.\n",
      "Added page 23 of document 0 to index.\n",
      "Added page 24 of document 0 to index.\n",
      "Added page 25 of document 0 to index.\n",
      "Added page 26 of document 0 to index.\n",
      "Added page 27 of document 0 to index.\n",
      "Added page 28 of document 0 to index.\n",
      "Added page 29 of document 0 to index.\n",
      "Added page 30 of document 0 to index.\n",
      "Added page 31 of document 0 to index.\n",
      "Added page 32 of document 0 to index.\n",
      "Added page 33 of document 0 to index.\n",
      "Added page 34 of document 0 to index.\n",
      "Added page 35 of document 0 to index.\n",
      "Added page 36 of document 0 to index.\n",
      "Added page 37 of document 0 to index.\n",
      "Added page 38 of document 0 to index.\n",
      "Added page 39 of document 0 to index.\n",
      "Added page 40 of document 0 to index.\n",
      "Added page 41 of document 0 to index.\n",
      "Index exported to .byaldi/finance_data\n",
      "Indexing file: finance/APAC_Tale of HK SAR _ SNG Report_short version_FINAL.pdf\n",
      "Added page 1 of document 1 to index.\n",
      "Added page 2 of document 1 to index.\n",
      "Added page 3 of document 1 to index.\n",
      "Added page 4 of document 1 to index.\n",
      "Added page 5 of document 1 to index.\n",
      "Added page 6 of document 1 to index.\n",
      "Added page 7 of document 1 to index.\n",
      "Added page 8 of document 1 to index.\n",
      "Added page 9 of document 1 to index.\n",
      "Added page 10 of document 1 to index.\n",
      "Added page 11 of document 1 to index.\n",
      "Added page 12 of document 1 to index.\n",
      "Added page 13 of document 1 to index.\n",
      "Added page 14 of document 1 to index.\n",
      "Added page 15 of document 1 to index.\n",
      "Added page 16 of document 1 to index.\n",
      "Added page 17 of document 1 to index.\n",
      "Added page 18 of document 1 to index.\n",
      "Added page 19 of document 1 to index.\n",
      "Added page 20 of document 1 to index.\n",
      "Added page 21 of document 1 to index.\n",
      "Added page 22 of document 1 to index.\n",
      "Added page 23 of document 1 to index.\n",
      "Added page 24 of document 1 to index.\n",
      "Added page 25 of document 1 to index.\n",
      "Added page 26 of document 1 to index.\n",
      "Added page 27 of document 1 to index.\n",
      "Added page 28 of document 1 to index.\n",
      "Added page 29 of document 1 to index.\n",
      "Index exported to .byaldi/finance_data\n",
      "Index exported to .byaldi/finance_data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'finance/jll-asia-pacific-capital-tracker-3q23 (1).pdf',\n",
       " 1: 'finance/APAC_Tale of HK SAR _ SNG Report_short version_FINAL.pdf'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from byaldi import RAGMultiModalModel\n",
    "\n",
    "INDEX_NAME = \"finance_data\"\n",
    "RAG = RAGMultiModalModel.from_pretrained(\"vidore/colpali-v1.2\")\n",
    "\n",
    "RAG.index(\n",
    "    input_path=\"finance/\", # The path to your documents\n",
    "    index_name=INDEX_NAME, # The name you want to give to your index. It'll be saved at `index_root/index_name/`.\n",
    "    store_collection_with_index=True, # Whether the index should store the base64 encoded documents.\n",
    "    # doc_ids=[0, 1, 2], # Optionally, you can specify a list of document IDs. They must be integers and match the number of documents you're passing. Otherwise, doc_ids will be automatically created.\n",
    "    # metadata=[{\"author\": \"John Doe\", \"date\": \"2021-01-01\"}], # Optionally, you can specify a list of metadata for each document. They must be a list of dictionaries, with the same length as the number of documents you're passing.\n",
    "    overwrite=True # Whether to overwrite an index if it already exists. If False, it'll return None and do nothing if `index_root/index_name` exists.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using in-memory collection. This means every image is stored in memory.\n",
      "You might want to rethink this if you have a large collection!\n",
      "Loaded 70 images from 1 JSON files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/recoverx/astarag/VisualFinanceAgent/.venv/lib/python3.10/site-packages/byaldi/colpali.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.indexed_embeddings.extend(torch.load(file))\n"
     ]
    }
   ],
   "source": [
    "search_index = RAG.from_index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "res = search_index.search(query=\"How many companies are leaving Hong Kong\",k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF TO IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He.loo', 'asd']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"He.loo.asd\"\n",
    "s.rsplit(\".\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from pdf2image import convert_from_path\n",
    "# from PIL import Image\n",
    "# import multiprocessing\n",
    "\n",
    "# def process_pdf(args):\n",
    "#     pdf_file, input_dir, output_dir = args\n",
    "#     pdf_path = os.path.join(input_dir, pdf_file)\n",
    "#     curr_output_dir = os.path.join(output_dir, pdf_file[:-4])  # Remove .pdf extension\n",
    "#     os.makedirs(curr_output_dir, exist_ok=True)\n",
    "    \n",
    "#     images = convert_from_path(pdf_path)\n",
    "#     for i, image in enumerate(images):\n",
    "#         image_path = os.path.join(curr_output_dir, f'page_{i+1}.png')\n",
    "#         image.save(image_path, 'PNG')\n",
    "    \n",
    "#     print(f\"Processed: {pdf_file}\")\n",
    "\n",
    "# def pdf_to_png_parallel(input_dir, output_dir):\n",
    "#     # Create output directory if it doesn't exist\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#     # Get list of PDF files\n",
    "#     pdf_files = [f for f in os.listdir(input_dir) if f.endswith('.pdf')]\n",
    "\n",
    "#     # Prepare arguments for multiprocessing\n",
    "#     args = [(pdf_file, input_dir, output_dir) for pdf_file in pdf_files]\n",
    "\n",
    "#     # Use all available CPU cores\n",
    "#     num_processes = multiprocessing.cpu_count()\n",
    "\n",
    "#     # Create a pool of worker processes\n",
    "#     with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "#         # Map the process_pdf function to all arguments\n",
    "#         pool.map(process_pdf, args)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     input_dir = 'finance'  # Directory containing PDF files\n",
    "#     output_dir = 'output_png2_files'\n",
    "#     pdf_to_png_parallel(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import AsyncGroq\n",
    "import base64\n",
    "import os\n",
    "import asyncio\n",
    "from typing import List, Optional, Annotated\n",
    "from pydantic import BaseModel\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "client = AsyncGroq(api_key=os.environ['GROQ_API_KEY'])\n",
    "\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Data model for LLM to generate\n",
    "class SummaryResponse(BaseModel):\n",
    "    summary: Annotated[str, \"Summary of the image in 2-3 lines that briefly describes the image\"]\n",
    "    keywords: Annotated[List[str], \"List of keywords mentioned in the page\"]\n",
    "\n",
    "\n",
    "async def get_summary(base64_enc: str) -> SummaryResponse:\n",
    "    completion = await client.chat.completions.create(\n",
    "    model=\"llama-3.2-11b-vision-preview\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Summarize the image in 2-3 lines\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{encode_image(base64_enc)}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=False,\n",
    "    # response_format={\"type\": \"json_object\"},\n",
    "    stop=None,\n",
    "    )\n",
    "    # return SummaryResponse.model_validate_json(chat_completion.choices[0].message.content)\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "recipe = await get_summary(\"output_png2_files/jll-asia-pacific-capital-tracker-3q23 (1)/page_4.png\")\n",
    "# if __name__ == '__main__':\n",
    "    # summary = asyncio.run(get_summary(data['base_64']))\n",
    "# print_recipe(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image depicts a bar graph titled \"Currency hedging impact\", which visually represents the effects of currency hedging transactions on cross-currency returns. The graph features three sections: \"Depreciation of APAC currencies against USD\", \"Transaction volume changes by geography for 2012 vs. 2012\", and \"Policy rates by geography\", set against a background of informative text in narrative form.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_8.png\n",
      "page_29.json\n",
      "page_1.json\n",
      "page_37.json\n",
      "page_41.png\n",
      "page_32.png\n",
      "page_2.json\n",
      "page_13.png\n",
      "page_20.png\n",
      "page_41.json\n",
      "page_9.json\n",
      "page_12.png\n",
      "page_22.json\n",
      "page_18.png\n",
      "page_35.png\n",
      "page_19.png\n",
      "page_32.json\n",
      "page_30.json\n",
      "page_33.png\n",
      "page_7.json\n",
      "page_40.png\n",
      "page_34.json\n",
      "page_38.json\n",
      "page_3.png\n",
      "page_24.json\n",
      "page_30.png\n",
      "page_27.json\n",
      "page_25.png\n",
      "page_10.png\n",
      "page_11.png\n",
      "page_39.json\n",
      "page_14.json\n",
      "page_16.png\n",
      "page_21.json\n",
      "page_21.png\n",
      "page_31.json\n",
      "page_39.png\n",
      "page_17.png\n",
      "page_27.png\n",
      "page_33.json\n",
      "page_4.json\n",
      "page_22.png\n",
      "page_28.png\n",
      "page_16.json\n",
      "page_37.png\n",
      "page_14.png\n",
      "page_3.json\n",
      "page_11.json\n",
      "page_31.png\n",
      "page_5.json\n",
      "page_36.png\n",
      "page_26.png\n",
      "page_23.png\n",
      "page_35.json\n",
      "page_26.json\n",
      "page_6.png\n",
      "page_7.png\n",
      "page_6.json\n",
      "page_38.png\n",
      "page_19.json\n",
      "page_15.png\n",
      "page_2.png\n",
      "page_5.png\n",
      "page_1.png\n",
      "page_24.png\n",
      "page_36.json\n",
      "page_18.json\n",
      "page_8.json\n",
      "page_13.json\n",
      "page_40.json\n",
      "page_10.json\n",
      "page_29.png\n",
      "page_9.png\n",
      "page_17.json\n",
      "page_34.png\n",
      "page_20.json\n",
      "page_28.json\n",
      "page_12.json\n",
      "page_4.png\n",
      "page_25.json\n",
      "page_15.json\n",
      "page_23.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for d in os.listdir(\"visualfinanceagent/vectordb/output_imgs/jll-asia-pacific-capital-tracker-3q23 (1)\"):\n",
    "    if d.endswith(\".pdf\"):\n",
    "        metadata_path = d.rsplit(\".\")[0] + \".json\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# def organize_files(source_dir):\n",
    "#     # Create subdirectories\n",
    "#     png_dir = os.path.join(source_dir, \"PNG\")\n",
    "#     json_dir = os.path.join(source_dir, \"JSON\")\n",
    "    \n",
    "#     os.makedirs(png_dir, exist_ok=True)\n",
    "#     os.makedirs(json_dir, exist_ok=True)\n",
    "\n",
    "#     # Iterate through files in the source directory\n",
    "#     for filename in os.listdir(source_dir):\n",
    "#         file_path = os.path.join(source_dir, filename)\n",
    "        \n",
    "#         # Skip if it's not a file\n",
    "#         if not os.path.isfile(file_path):\n",
    "#             continue\n",
    "        \n",
    "#         # Move PNG files\n",
    "#         if filename.lower().endswith('.png'):\n",
    "#             shutil.move(file_path, os.path.join(png_dir, filename))\n",
    "#             print(f\"Moved {filename} to PNG directory\")\n",
    "        \n",
    "#         # Move JSON files\n",
    "#         elif filename.lower().endswith('.json'):\n",
    "#             shutil.move(file_path, os.path.join(json_dir, filename))\n",
    "#             print(f\"Moved {filename} to JSON directory\")\n",
    "\n",
    "# # Usage\n",
    "# source_directory = 'visualfinanceagent/vectordb/output_imgs_2/APAC_Tale of HK SAR _ SNG Report_short version_FINAL'\n",
    "# organize_files(source_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using in-memory collection. This means every image is stored in memory.\n",
      "You might want to rethink this if you have a large collection!\n",
      "Loaded 70 images from 1 JSON files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/recoverx/astarag/VisualFinanceAgent/.venv/lib/python3.10/site-packages/byaldi/colpali.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.indexed_embeddings.extend(torch.load(file))\n"
     ]
    }
   ],
   "source": [
    "from byaldi import RAGMultiModalModel\n",
    "\n",
    "rag_index = RAGMultiModalModel.from_index(index_path=\"finance_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "res = rag_index.search(\n",
    "    query=\"What did Hong Kong do better than Singapore?\",\n",
    "    k = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/recoverx/astarag/VisualFinanceAgent/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cuda','trust_remote_code':True}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "import os\n",
    "import json\n",
    "\n",
    "docs = []\n",
    "path = \"visualfinanceagent/vectordb/output_imgs_2\"\n",
    "for dir in os.listdir(path):\n",
    "    pdfs = os.path.join(path,dir)\n",
    "    for json_path in os.listdir(os.path.join(pdfs,\"JSON\")):\n",
    "        with open(os.path.join(pdfs,\"JSON\",json_path), 'r') as file:\n",
    "            data = json.load(file)\n",
    "        docs.append(Document(page_content=data['summary'],metadata={\"filename\":dir,\"page_num\":json_path}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(docs, hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'filename': 'APAC_Tale of HK SAR _ SNG Report_short version_FINAL', 'page_num': 'page_14.json'}, page_content=\"Hong Kong SAR maintains a deeper finance talent pool, while Singapore boasts stronger science and high value workers. In 2022, Hong Kong SAR's total employment and hiring surged ahead of Singapore's. The talent pool in both Hong Kong SAR and Singapore will continue to deepen in the long run.\"),\n",
       " Document(metadata={'filename': 'APAC_Tale of HK SAR _ SNG Report_short version_FINAL', 'page_num': 'page_15.json'}, page_content='There are significant disparities between foreign workers from Singapore and Hong Kong SAR. The number of Hong Kong SAR workers in Singapore and vice versa have both seen declines since 2018, with Singapore still having a higher number than Hong Kong SAR. \\n\\nPlease let me know if I can help with anything else.'),\n",
       " Document(metadata={'filename': 'APAC_Tale of HK SAR _ SNG Report_short version_FINAL', 'page_num': 'page_5.json'}, page_content=\"Hong Kong is in a cost disadvantage vs Singapore in almost all cost categories. The service sector contributes over 80% of Hong Kong's GDP. Higher value-added industries than Singapore's 50% are in Singapore.\"),\n",
       " Document(metadata={'filename': 'APAC_Tale of HK SAR _ SNG Report_short version_FINAL', 'page_num': 'page_28.json'}, page_content=\"Hong Kong SAR and Singapore demonstrate strong ties with their respective core missions. This is further highlighted by Hong Kong SAR's commercial roles and Singapore's investments in high-tech manufacturing.\")]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever.invoke(\"Difference between hong kong and singapore?\")\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/recoverx/astarag/VisualFinanceAgent/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using in-memory collection. This means every image is stored in memory.\n",
      "You might want to rethink this if you have a large collection!\n",
      "Loaded 70 images from 1 JSON files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/recoverx/astarag/VisualFinanceAgent/.venv/lib/python3.10/site-packages/byaldi/colpali.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.indexed_embeddings.extend(torch.load(file))\n",
      "/home/recoverx/astarag/VisualFinanceAgent/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pipeline import VisionFinancePipeLine\n",
    "\n",
    "vfsp = VisionFinancePipeLine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vfsp.vision_index.search(\"Hong Kong\",k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfsp.summary_index.invoke()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
